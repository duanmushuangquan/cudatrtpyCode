{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RingAllReduce\n",
    "* 环形聚拢计算（all reduce，减少，全部减少）\n",
    "* https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 认识关键词\n",
    "* 显卡数N，显卡的数量\n",
    "* 主机数，主机的数量，每个主机有N个显卡\n",
    "* Infiniband，无限带宽技术，IB\n",
    "    - 他修改了网络数据交换协议，而并非TCP/IP这种繁琐复杂的行为，使得内存可以远程直接访问而无需CPU介入，硬件层面直接实现，访问效率极高。百度测试的Infiniband设备带宽约6GB/s。GPU之间直接通信的RDMA速率高达10GB/s，而使用NVLINK桥接器后最高可达到200GB/s。通常我们使用的GPU是基于PCIE的通信，因此速率受限于PCIE的速度\n",
    "        - https://www.nvidia.cn/design-visualization/nvlink-bridges/\n",
    "* PCIE，PCI Express，(Peripheral Component Interconnect Express)高速串行计算扩展总线标准\n",
    "    - GPU插在主板上是用的PICE接口\n",
    "    - PCIE有1.0、2.0、3.0、4.0、5.0共5个版本，常见的有1.0、2.0、3.0，这里的5.0还没出现\n",
    "    - PCIE的接口有4种形式，即x1、x4、x8、x16，对应的是卡片的针脚数量的增多，相应的吞吐量也逐渐增大\n",
    "    <img src=\"pcie.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gpu.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PCIE的速率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"speed.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于通信模式的划分\n",
    "### DataParallel模式(DP)，Parameter Center模式，主从模式（主卡收集梯度，从卡发送参数和接受结果）\n",
    "- 速度的瓶颈是任意显卡x到主显卡0这个通路的速度和总带宽，以及显卡数量（越多其实影响越大）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"master-slave-gpus.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* D = 模型参数总量，设为1GB\n",
    "* S = 单条线路的传输速率，设为1GB/s，也就是任何显卡传数据到GPU0，或者传输出去都是最大1GB/s\n",
    "* N = 显卡的个数，这里为5\n",
    "* 完成N个显卡之间的参数平均以及更新，需要以下步骤：\n",
    "    1. Scatter-Reduce，GPU1、GPU2、GPU3、GPU4将模型参数发送给GPU0，并在GPU0上完成累加求平均\n",
    "        - 此时所有数据都要经过GPU0，并且无法并行，GPU0的接口速率决定时长\n",
    "    2. Allgather，GPU0将平均后的参数发送给4个卡\n",
    "        - 依旧经过GPU0，无法并行\n",
    "* 由以上定义，我们可以推算出，\n",
    "    - 数据的传输量为4 x D x 2，我们经过了1次Scatter Reduce传输了4D数据量，经过了1次Allgather传输了4D数据量\n",
    "    - 我们传输耗时理论为4 x 2 x D / S，得到结果约为8秒，公式为：$$ Times = 2(N-1) \\cdot \\frac{D}{S} $$\n",
    "    - 我们传输的数据总量（**显卡数相关**）：$$ Data Transferred = 2(N-1) \\cdot D $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于通信模式的划分\n",
    "### DistributedDataParallel模式(DDP)，Ring模式，环形模式\n",
    "- 要求显卡间相互连接，组成环状，每个显卡都可以发送和接受相邻显卡的数据\n",
    "- 由于相邻显卡间是独立的线路，相互不干扰，所以传输瓶颈是单个线路的速度和带宽，不受显卡数量影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ring-gpus.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* D = 模型参数总量，设为1GB\n",
    "* S = 单条线路的传输速率，设为1GB/s，也就是任何显卡传数据到GPU0，或者传输出去都是最大1GB/s\n",
    "* N = 显卡的个数，这里为5\n",
    "* 完成N个显卡之间的参数平均以及更新，需要以下步骤：\n",
    "    1. 将数据划分为N份\n",
    "    2. Scatter-Reduce\n",
    "        - 循环N-1次\n",
    "            - 将N个卡，每个卡都传递其显卡索引对应的那份数据，给相邻的下一个显卡做累加\n",
    "                - 这个操作是同步进行的，因为传递所使用的线路是相邻显卡路径，不存在等待堆积\n",
    "                - 也因此这里执行一次所消耗的时间，其实是$\\frac{1}{N}$\n",
    "                - 当然，如果显卡无法构成环形的，都走PCIE总线，那么PCIE总线的速度上限就是约束，而PCIE总线一般是8GB以上，这依旧比1GB/s显卡单向访问要快\n",
    "    3. Allgather\n",
    "        - 将累加后的数据计算平均得到均值\n",
    "        - 循环N-1次\n",
    "            - 将每个卡中存在的完整数据发送给相邻下一个卡\n",
    "            - 也因此这里执行一次所消耗的时间，其实是$\\frac{1}{N}$\n",
    "            - 这里也是可以并行，如果没有环形结构，走PCIE总线，那么PCIE速度会限制\n",
    "* 根据上面描述，我们可以推算出：\n",
    "    1. 我们Scatter-Reduce时经过了N-1次$\\frac{1}{N}$大小的数据传输，耗时认为是$\\frac{D}{S} \\cdot \\frac{1}{N} \\cdot (N-1) $\n",
    "    2. 我们Allgather时经过了N-1次$\\frac{1}{N}$大小的数据传输，耗时认为是$\\frac{D}{S} \\cdot \\frac{1}{N} \\cdot (N-1) $\n",
    "    3. 因此传输的耗时为：$Times = 2(N-1) \\cdot \\frac{1}{N} \\cdot \\frac{D}{S}$\n",
    "    4. 传输的数据量为：$Data Transferred = 2(N-1) \\cdot \\frac{D}{N}$\n",
    "        - 需要注意的是，这里的数据传输量，与显卡数N无关\n",
    "        - 他的传输速度受限于环之间的数据传输速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter-Reduce阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"array-partition.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scatter-reduce-iteration-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scatter-reduce-iteration-2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scatter-reduce-iteration-3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scatter-reduce-iteration-4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Reduce结束后的样子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scatter-reduce-iteration-done.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgather阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"allgather-iteration-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"allgather-iteration-2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"allgather-iteration-3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"allgather-iteration-4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgather结束后的样子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"allgather-iteration-done.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "1. DP模式下的主从模式，通信速度受限于单个显卡的通信速率。传递的数据量为$2(N-1)D$\n",
    "    - N为显卡数，D为模型参数大小\n",
    "2. DDP模式下的RingAllReduce，通信速度受限于显卡邻居间通信速率\n",
    "    - 于PCIE下，受限于主板的PCIE速度，而不是显卡的速度\n",
    "    - 于NVLINK下则最高可达100GB/s甚至更高\n",
    "    - 传递的数据量为$2(N-1)\\frac{D}{N}$，与显卡数量无关，也因此其效率高"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
